{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Import the data from Edge Impulse. You can obtain the URL from the Dashboard, right-click on the download icon next to 'Spectral features data' and 'Spectral features labels', and click **Copy link location**."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "import numpy as np\n",
                "import requests\n",
                "\n",
                "API_KEY = 'ei_29890ae8d6c3747a7ed91385afcbfe2ba815fe537d0a905ff7d17dcbe6127bbe'\n",
                "\n",
                "X = (requests.get('https://studio.edgeimpulse.com/v1/api/24937/training/5/x', headers={'x-api-key': API_KEY})).content\n",
                "Y = (requests.get('https://studio.edgeimpulse.com/v1/api/24937/training/5/y', headers={'x-api-key': API_KEY})).content"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Store the data in a temporary file, and load it back through Numpy."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "with open('x_train.npy', 'wb') as file:\n",
                "    file.write(X)\n",
                "with open('y_train.npy', 'wb') as file:\n",
                "    file.write(Y)\n",
                "X = np.load('x_train.npy')\n",
                "Y = np.load('y_train.npy')[:,0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Define our labels and split the data up in a test and training set:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "import sys, os, random\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "import logging\n",
                "tf.get_logger().setLevel(logging.ERROR)\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
                "\n",
                "# Set random seeds for repeatable results\n",
                "RANDOM_SEED = 3\n",
                "random.seed(RANDOM_SEED)\n",
                "np.random.seed(RANDOM_SEED)\n",
                "tf.random.set_seed(RANDOM_SEED)\n",
                "\n",
                "classes_values = [ \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\", \"109\", \"66\", \"67\", \"68\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"76\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"85\", \"86\", \"87\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"95\", \"96\", \"97\", \"98\", \"99\", \"Eight\", \"Eighteen\", \"Eleven\", \"Fifteen\", \"Fifty\", \"Fifty-eight\", \"Fifty-five\", \"Fifty-four\", \"Fifty-nine\", \"Fifty-one\", \"Fifty-seven\", \"Fifty-six\", \"Fifty-three\", \"Fifty-two\", \"Five\", \"Forty\", \"Forty-eight\", \"Forty-five\", \"Forty-four\", \"Forty-nine\", \"Forty-one\", \"Forty-seven\", \"Forty-six\", \"Forty-three\", \"Forty-two\", \"Four\", \"Fourteen\", \"Nineteen\", \"One\", \"Seven\", \"Seventeen\", \"Six\", \"Sixteen\", \"Sixty\", \"Sixty-five\", \"Sixty-four\", \"Sixty-one\", \"Sixty-three\", \"Sixty-two\", \"Thirty\", \"Thirty-eight\", \"Thirty-five\", \"Thirty-four\", \"Thirty-nine\", \"Thirty-one\", \"Thirty-seven\", \"Thirty-six\", \"Thirty-three\", \"Thirty-two\", \"Three\", \"Twenty\", \"Twenty-eight\", \"Twenty-five\", \"Twenty-four\", \"Twenty-nine\", \"Twenty-one\", \"Twenty-seven\", \"Twenty-six\", \"Twenty-three\", \"Twenty-two\", \"Two\", \"Zero\" ]\n",
                "classes = len(classes_values)\n",
                "\n",
                "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
                "\n",
                "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
                "\n",
                "input_length = X_train[0].shape[0]\n",
                "\n",
                "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
                "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
                "\n",
                "def set_batch_size(batch_size, train_dataset, validation_dataset):\n",
                "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
                "    validation_dataset = validation_dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
                "    return train_dataset, validation_dataset\n",
                "\n",
                "callbacks = []\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Train the model:"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "\n",
                "# model architecture\n",
                "model = Sequential()\n",
                "model.add(Conv2D(48, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
                "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
                "model.add(Conv2D(48, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
                "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
                "model.add(Conv2D(48, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
                "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
                "model.add(Dropout(0.1))\n",
                "model.add(Conv2D(16, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
                "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
                "model.add(Conv2D(16, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
                "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
                "model.add(Conv2D(16, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
                "model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
                "model.add(Dropout(0.1))\n",
                "model.add(Flatten())\n",
                "model.add(Dropout(0.1))\n",
                "model.add(Dense(classes, activation='softmax', name='y_pred'))\n",
                "\n",
                "# this controls the learning rate\n",
                "opt = Adam(lr=0.0002, beta_1=0.9, beta_2=0.999)\n",
                "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
                "BATCH_SIZE = 32\n",
                "train_dataset, validation_dataset = set_batch_size(BATCH_SIZE, train_dataset, validation_dataset)\n",
                "\n",
                "# train the neural network\n",
                "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
                "model.fit(train_dataset, epochs=50, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# Save the model to disk\n",
                "model.save('saved_model')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}